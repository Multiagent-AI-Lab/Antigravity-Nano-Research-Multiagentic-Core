# Unidad 3: Machine Learning para Nanomateriales

**Fundamentos de ML y Redes Neuronales aplicadas a Nanociencia**

---

## üéØ Objetivos de Aprendizaje

Al completar esta unidad, ser√°s capaz de:

1. ‚úÖ Comprender los fundamentos matem√°ticos del Machine Learning
2. ‚úÖ Aplicar algoritmos cl√°sicos de ML a datos de nanomateriales
3. ‚úÖ Dise√±ar y entrenar redes neuronales para predicci√≥n de propiedades
4. ‚úÖ Preprocesar datos experimentales y de simulaci√≥n para ML
5. ‚úÖ Evaluar y validar modelos con m√©tricas cient√≠ficas apropiadas
6. ‚úÖ Interpretar modelos desde una perspectiva qu√≠mica y f√≠sica

---

## üìã Contenido

Esta unidad se divide en **dos partes complementarias**:

### Parte 1: Fundamentos de Machine Learning
**Notebook**: `UNIDAD_3_ML_FUNDAMENTOS.ipynb`

**Contenido**:
- Introducci√≥n al aprendizaje autom√°tico: supervisado, no supervisado, por refuerzo
- Regresi√≥n lineal y log√≠stica con interpretaci√≥n f√≠sica
- √Årboles de decisi√≥n y Random Forest para clasificaci√≥n de materiales
- Support Vector Machines (SVM) para propiedades de nanomateriales
- Feature engineering: descriptores moleculares y cristalogr√°ficos
- Validaci√≥n cruzada y m√©tricas de evaluaci√≥n cient√≠fica

### Parte 2: Redes Neuronales
**Notebook**: `UNIDAD_3_PARTE2_REDES_NEURONALES.ipynb`

**Contenido**:
- Fundamentos matem√°ticos: perceptr√≥n, retropropagaci√≥n, funciones de activaci√≥n
- Arquitecturas profundas (DNN) para predicci√≥n de propiedades
- Redes neuronales de grafos (GNN) para mol√©culas y cristales
- Redes convolucionales (CNN) para im√°genes de microscop√≠a
- Transferencia de aprendizaje en aplicaciones nanoscient√≠ficas
- Interpretabilidad: SHAP values, mapas de atenci√≥n

---

## üõ†Ô∏è Requisitos T√©cnicos

### Ambiente Conda

```bash
conda activate ia_nano
```

### Dependencias Principales

**Para Parte 1 (ML Cl√°sico)**:
- **Scikit-learn** - Algoritmos de ML
- **NumPy**, **Pandas** - Manejo de datos
- **Matplotlib**, **Seaborn** - Visualizaci√≥n
- **Matminer** - Descriptores de materiales

**Para Parte 2 (Redes Neuronales)**:
- **TensorFlow** o **PyTorch** - Frameworks de Deep Learning
- **PyTorch Geometric** - GNN para mol√©culas (opcional)
- **SHAP** - Interpretabilidad de modelos

---

## üöÄ C√≥mo Ejecutar

```bash
cd educational_content/unit_03_ml_nanomaterials

# Parte 1: ML Fundamentos
jupyter lab UNIDAD_3_ML_FUNDAMENTOS.ipynb

# Parte 2: Redes Neuronales
jupyter lab UNIDAD_3_PARTE2_REDES_NEURONALES.ipynb
```

---

## üéì Nivel y Duraci√≥n

- **Nivel**: Licenciatura avanzada - Posgrado
- **Prerrequisitos**:
  - Completar Unidades 1 y 2
  - √Ålgebra lineal b√°sica
  - C√°lculo diferencial (para gradientes)
  - Python intermedio (NumPy, Pandas)
- **Duraci√≥n estimada**:
  - Parte 1: 4-5 horas
  - Parte 2: 5-6 horas
  - **Total**: 9-11 horas

---

## üß™ Conceptos Clave

### ML Cl√°sico (Parte 1)

- **Supervisado**: Aprender mapeo input‚Üíoutput con datos etiquetados
- **Feature engineering**: Descriptores moleculares (fingerprints, Coulomb matrix)
- **Bias-Variance tradeoff**: Balance entre underfitting y overfitting
- **Cross-validation**: Evaluaci√≥n robusta con datos limitados
- **Random Forest**: Ensemble de √°rboles, robusto y explicable

### Redes Neuronales (Parte 2)

- **Retropropagaci√≥n**: Algoritmo para ajuste de pesos por gradiente
- **Funci√≥n de activaci√≥n**: ReLU, Sigmoid, Tanh y su impacto f√≠sico
- **Dropout**: Regularizaci√≥n para evitar sobreajuste
- **GNN (Graph Neural Networks)**: Representaci√≥n natural de mol√©culas como grafos
- **Transfer learning**: Reutilizar modelos preentrenados en nuevos dominios

---

## üìö Referencias Cient√≠ficas

1. **Goodfellow, Bengio & Courville** (2016). "Deep Learning." MIT Press.
2. **G√©ron** (2022). "Hands-On Machine Learning." O'Reilly.
3. **Duvenaud et al.** (2015). "Convolutional Networks on Graphs for Learning Molecular Fingerprints." *NeurIPS*.
4. **Sch√ºtt et al.** (2017). "SchNet: A continuous-filter convolutional neural network for modeling quantum interactions." *NeurIPS*.
5. **Brockherde et al.** (2017). "Bypassing the Kohn-Sham equations with machine learning." *Nature Comm.* 8, 872.

---

## ‚úÖ Checklist de Aprendizaje

### Parte 1: ML Cl√°sico
- [ ] Distinguir tipos de aprendizaje autom√°tico y cu√°ndo usar cada uno
- [ ] Calcular y interpretar m√©tricas (RMSE, R¬≤, MAE, F1)
- [ ] Construir pipeline completo: datos ‚Üí features ‚Üí modelo ‚Üí validaci√≥n
- [ ] Aplicar Random Forest a predicci√≥n de propiedades
- [ ] Generar e interpretar descriptores moleculares

### Parte 2: Redes Neuronales
- [ ] Dise√±ar arquitecturas DNN apropiadas al problema
- [ ] Entrenar redes con optimizaci√≥n por gradiente descendente
- [ ] Aplicar t√©cnicas de regularizaci√≥n (Dropout, L2)
- [ ] Implementar una GNN simple para mol√©culas
- [ ] Interpretar predicciones con SHAP values

---

## üîÑ Conexi√≥n con Otras Unidades

**De Unidad 2**: Los descriptores estructurales (RDF, n√∫mero de coordinaci√≥n) se usan como features de entrada para los modelos de ML

**Hacia Unidad 4**: Los modelos entrenados aqu√≠ se integran con datos experimentales reales

---

## üêõ Troubleshooting

### Error: "No module named 'torch'"

```bash
conda activate ia_nano
conda install pytorch torchvision -c pytorch
```

### Error: "No module named 'matminer'"

```bash
pip install matminer
```

### Memoria insuficiente al entrenar

```python
# Reducir batch_size
trainer = Trainer(batch_size=16)  # en vez de 64

# O reducir el dataset inicial
X_train_small = X_train[:1000]
```

Ver [INSTALL.md](../../INSTALL.md) para m√°s soluciones.

---

## ü§ù Contribuir

1. Abre un [Issue](https://github.com/ljyudico/Antigravity-Nano-Research-Multiagentic-Core/issues)
2. Etiqueta con `unit-3` y `educational-content`

---

<div align="center">
  <sub>Machine Learning aplicado a la frontera de la investigaci√≥n en nanomateriales ü§ñüî¨</sub>
</div>
